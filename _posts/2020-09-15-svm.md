---
title: 5.DigitRecognition - SVM algorithm
excerpt: Computer Vision


#최상위 사진
header:
  image: /assets/images/foo-bar-identity.jpg
  teaser: /assets/images/foo-bar-identity-th.jpg

gallery:
  - url: /assets/images/unsplash-gallery-image-1.jpg
    image_path: assets/images/unsplash-gallery-image-1-th.jpg
    alt: "placeholder image 1"
  - url: /assets/images/unsplash-gallery-image-2.jpg
    image_path: assets/images/unsplash-gallery-image-2-th.jpg
    alt: "placeholder image 2"
  - url: /assets/images/unsplash-gallery-image-3.jpg
    image_path: assets/images/unsplash-gallery-image-3-th.jpg
    alt: "placeholder image 3"
    


 #사이드바 설정 
sidebar:
  - title: "Role"
    nav: sidebar-sample

# 해당 글 목차
toc: true
toc_sticky: true

toc_label: "Yimsu's Blog"
toc_icon: "cog"


## 테그설정

categories:
  - ComputerVision
  - Portfolio
tags: "ComputerVision"

---


### SVM algorithm

<br/>
<br/>

### 1. SVM algorithm
<br/>

- What is support vector machine algorithm?
    - The method that divide into data and furthest hyper plane, and then make tow group. 



<br/>

![image](/assets/images/computervision/20200915_1.png)

<br/>

- Max margine hyper plane
    - hyper plane : w * x + b = 0
    - To seek w which make max margin ( ![image](/assets/images/computervision/20200915_2.png) )



<br/>

![image](/assets/images/computervision/20200915_3.png)

<br/>


![image](/assets/images/computervision/20200915_4.png)

<br/>

- How to solve?
    -> define Constrainsts, Lagrange multiplier, KTT condition, etc

- The solution
    -> The optimal solution for seperating the given data.

- Allow misclassification
    - If the given sample is couldn't divided perfectly two group, Misclassification is allowed.



<br/>

![image](/assets/images/computervision/20200915_5.png)

<br/>

![image](/assets/images/computervision/20200915_6.png)

<br/>

- C value is parameter set by user
- If C value is high, misclassification error will be low but margin is also to be low



<br/>

- Seperating non-linear data 
    - SVM is linear classification algorithm but real data are could distributed to non-linear.
    - If dimension of non-linear data is expaned, it could seperated
    - Example of dimension expand

![image](/assets/images/computervision/20200916_1.png)


<br/>

- kernel trick
    - This method use the non-linear kernel function which replace dot product operation of vector in SVM hyper plane instead of using directly mapping function.


<br/>

- Main kernel function
    -Polynominal : ![image](/assets/images/computervision/20200916_2.png)
- Radial basis function : ![image](/assets/images/computervision/20200916_3.png)
    - If gamma vlaue is high, it is very dependent on train data -> complex decision plane -> possiblity of overfitting will be high/

<br/>
<br/>

### 2. Use OpenCV SVM

<br/>

- Genearate SVM object

``` c
cv2.ml.SVM_create() -> retval
```

- retval : cv2.ml_SVM object

<br/>

- Set SVM type

``` c
cv.ml_SVM.setType(type) -> None
```

type : sort of SVM

<br/>

- Set SVM kernel

``` c
cv.ml_SVM.setKernel(kernelType) -> None
```

- kernelType : type of kernel function


<br/>

- SVM automatic trian( k-fold cross validation)

``` c
cv.ml_SVM.trainAuto(samples, layout, reponses, kFold=None, ...) -> retva;
```

- samples : train data matrix
- layout : train data set method
- responses : response vector to each train data
- kFold : part set number for cross validation
- retval : If train complete nomally, it is True

<br/>
<br/>

### 3. HOG & SVM digit recognition


<br/>

- SVM trainning using for HOG feature vector


![image](/assets/images/computervision/20200916_5.png)

<br/>

- HOG & SVM digit recognition example



![image](/assets/images/computervision/20200916_6.png)

<br/>
